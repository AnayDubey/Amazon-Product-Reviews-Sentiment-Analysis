{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Amazon Product Reviews Sentiment Analysis\n", "This notebook performs sentiment analysis on Amazon product reviews using VADER sentiment analysis from the NLTK library. The code has been enhanced for better error handling, text preprocessing, and visualization."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import necessary packages\n", "import pandas as pd\n", "import nltk\n", "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n", "import matplotlib.pyplot as plt\n", "from wordcloud import WordCloud\n", "import re\n", "\n", "# Download VADER lexicon\n", "nltk.download('vader_lexicon')\n", "\n", "# Initialize the sentiment analyzer\n", "sentiments = SentimentIntensityAnalyzer()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load the dataset with error handling\n", "try:\n", "    data = pd.read_csv('amazon_reviews.csv')\n", "    print(f\"Data loaded successfully with {len(data)} entries\")\n", "except FileNotFoundError:\n", "    print(\"Error: CSV file not found. Please ensure the file is in the correct location.\")\n", "    exit()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Basic data cleaning\n", "# Handling missing data\n", "data = data.dropna(subset=['reviewText'])\n", "print(f\"Data after removing missing reviews: {len(data)} entries\")\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Text preprocessing function\n", "def preprocess_text(text):\n", "    # Remove non-alphabetic characters, convert to lowercase, and strip whitespace\n", "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n", "    text = text.lower().strip()\n", "    return text\n", "\n", "# Apply text preprocessing\n", "data['cleaned_reviews'] = data['reviewText'].apply(preprocess_text)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sentiment Analysis: Adding Positive, Negative, and Neutral columns\n", "data['Positive'] = data['cleaned_reviews'].apply(lambda review: sentiments.polarity_scores(review)['pos'])\n", "data['Negative'] = data['cleaned_reviews'].apply(lambda review: sentiments.polarity_scores(review)['neg'])\n", "data['Neutral'] = data['cleaned_reviews'].apply(lambda review: sentiments.polarity_scores(review)['neu'])\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Summarizing the sentiment scores\n", "positive_sum = data['Positive'].sum()\n", "negative_sum = data['Negative'].sum()\n", "neutral_sum = data['Neutral'].sum()\n", "\n", "# Print the summary of sentiment scores\n", "print(\"Sentiment Summary:\")\n", "print(f\"Positive Sentiment: {positive_sum}\")\n", "print(f\"Negative Sentiment: {negative_sum}\")\n", "print(f\"Neutral Sentiment: {neutral_sum}\")\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Visualize sentiment distribution as a pie chart\n", "labels = ['Positive', 'Negative', 'Neutral']\n", "sizes = [positive_sum, negative_sum, neutral_sum]\n", "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n", "explode = (0.1, 0, 0)  # Explode the first slice (Positive)\n", "\n", "plt.figure(figsize=(8, 8))\n", "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\n", "plt.title('Sentiment Distribution of Amazon Reviews')\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Visualize the word cloud of the reviews\n", "all_reviews = ' '.join(data['cleaned_reviews'])\n", "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_reviews)\n", "\n", "plt.figure(figsize=(10, 5))\n", "plt.imshow(wordcloud, interpolation='bilinear')\n", "plt.axis('off')\n", "plt.title('Word Cloud of Amazon Reviews')\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Display the first few rows of the processed data\n", "print('Processed Data Sample:')\n", "print(data.head())"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 4}